# Example of a config file for the workflow
# You have a lot of freedom in how you structure your config file, but keep in mind that the YAML will
# be converted to a python dictionary. This means that you can't have two entries with the same name at the same level.

# The contents of this file control the workflow. The highest level entries are the tasks to accomplish.
# Below the task level are the elements required for the task. For example, the task 'extract' iterates
# over 'reconstruction' data and 'simulation' data, the two sections specifying what (data, variables, time periods)
# to extract and how (region, attributes, subsequent saving) to do that. For the 'regrid' tasks, among other,
# the 'input' and 'output' data are specified along with the methodology for the regridding process.

# Note that some information is 'outsourced' to a separate 'paths1_example.yml' file. The contents of the two files will be
# merged in the CONFIG dictionary when the configuration is loaded. The configuration also contains the names
# of the 'properties1.yml' and 'indicators1.yml' files to draw their information for the respective tasks.

# The inputs listed in this configuration file are used in two different ways:
#
# 1) Direct 'manual' access during the workflow, with usage like a dictionary (e.g. CONFIG["regrid"]["inputs"])
#    No specific format is prescribed here, it can be anything you want. It would be good practice to put those entries
#    under the associated module or task name, to find them more easily in your workflow.
#    Only arguments that differ from the function defaults need to be specified.
#    Example usage during the workflow: results = xscen.search_data_catalogs(**CONFIG["extract"]["reconstruction"]["search_data_catalogs"])
#
# 2) Arguments that will be automatically passed to xscen functions.
#    For example the dictionary in CONFIG["regrid"]["regrid_dataset"] will be passed to xscen.regrid_dataset(...).
#    For this to work, the CONFIG must follow a very specific structure.
#    module:
#      function:
#        argument_1: value_a
#        argument_2: value_b
#    This only works on functions that are decorated with @parse_config in the xscen code.
#    Only arguments that differ from the function defaults need to be specified.
#    In this example configuration file, those instances are marked by "# automatically passed to the function."
#    Example usage during the workflow: ds_regrid = xscen.regrid_dataset(ds)
#    Note that you can always explicitly pass arguments to the function. These arguments will override the ones in the config.
#
# You can learn more about how the config works here: https://xscen.readthedocs.io/en/latest/notebooks/6_config.html

# List of task to accomplish in the workflow
# Each task will iterate over all simulations before moving on to the next task.
# It might be useful to start by running it once over all tasks on a single simulation
# (by modifying extract:simulation:search_data_catalogs:other_search_criteria:)
# to make sure all tasks work properly before launching it for all simulations.
tasks:
  - extract # Extract the simulation and reference dataset with the right domain and period.
  - regrid # Regrid the simulation onto the reference grid.
  - biasadjust # Train and adjust the simulation dataset one variable at the time.
  - cleanup # Join each individually adjusted variable back in one scenario dataset and clean up other details.
  - rechunk # Rechunk the scenario dataset and save it.
  - diagnostics # Compute diagnostics (properties, measures and summaries)
  - indicators # Compute xclim indicators on the scenario.
  - climatology # Compute the climatological mean of the indicators
  - delta # Compute the deltas of the climatological means.
  - ensembles # Compute the ensemble statistics on indicators, climatology and deltas.


# Task Arguments
extract:
  # The following ('reconstruction') is NOT automatically passed to the function because
  # the format is module:other_word:function (other_word=reconstruction).
  # It is dealt with manually in workflow1.py, building a loop over all entries below 'extract:'.
  # We do this here because we need a different set of arguments for the reconstruction and simulations.
  reconstruction:
    dask: # these arguments will need to be passed manually to the dask client
      n_workers: 2
      threads_per_worker: 3
      memory_limit: 15GB
    search_data_catalogs: # these arguments will be passed manually to xs.search_data_catalogs
      variables_and_freqs: &var_and_freq # this is an anchor. more on anchors:  https://support.atlassian.com/bitbucket-cloud/docs/yaml-anchors/
        tasmax: D
        tasmin: D
        pr: D
        dtr: D
      allow_resampling: False
      allow_conversion: True
      periods: &ref_period
        - '1991'
        - '2020'
      other_search_criteria:
        source: # put the reference you want here
          "ERA5-Land"
      # below are more possible arguments for the function xs.search_data_catalogs,
      # In this example, they are not needed in the config. Only entries that differ from the function defaults need to be specified.
      #exclusions:
      #match_hist_and_fut:
      #coverage_kwargs:
      #id_columns:
      #conversion_yaml:
      #restrict_resolution:
      #restrict_members:
      #restrict_warming_level:
    extract_dataset: # these arguments will be passed manually to xs.extract_dataset
      region: &region
        name: test1
        method: bbox
        tile_buffer: 1.5
        lon_bnds: [ -80, -79 ]
        lat_bnds: [ 44, 44.2 ]
      #variables_and_freqs:
      #periods:
      #to_level:
      #ensure_correct_time:
      #xr_open_kwargs:
      #xr_combine_kwargs:
      #preprocess:
      #resample_methods:
      #mask:
    stack_drop_nans: &stack
      True
    save:
      mode: o
      encoding:
        tasmax: &f32
          dtype: float32
        tasmin:
          dtype: float32
        pr:
          dtype: float32
        dtr:
          dtype: float32
      rechunk:
        time: -1
        loc: 10
      #zarr_kwargs:
      #compute:
      #itervar:
      #timeout_cleanup:
  simulation:
    dask:
      n_workers: 2
      threads_per_worker: 3
      memory_limit: 10GB
    search_data_catalogs:
      variables_and_freqs: *var_and_freq
      match_hist_and_fut: True
      allow_conversion: True
      allow_resampling: False
      periods: &sim_period
        - '1950'
        - '2100'
      other_search_criteria: # put the simulations you want here
        mip_era: CMIP6
        experiment:
          - ssp245
          - ssp370
        source:
          - CMCC-ESM2
          - KACE-1-0-G
        member:
          - r1i1p1f1
    extract_dataset:
      xr_combine_kwargs:
        combine_attrs: override
      xr_open_kwargs:
        drop_variables:
          - height
        chunks:
          lat: 10
          lon: 10
          time: 365
      region: *region
    floor: D
    save:
      mode: o
      encoding:
        tasmax: *f32
        tasmin: *f32
        pr: *f32
        dtr: *f32
      rechunk:
        lat: -1
        lon: -1
        time: 365


regrid:
  dask:
    n_workers: 2
    threads_per_worker: 5
    memory_limit: 10GB
  inputs:
    type: simulation
    processing_level: extracted
  output:
    type: reconstruction
    processing_level: extracted
  regrid_dataset: # automatically passed to the function (module name is regrid)
    regridder_kwargs:
      method: bilinear
      extrap_method: inverse_dist
      locstream_out: *stack
      reuse_weights: False
    #intermediate_grids:
    #to_level:
  save: &save_time_-1
    mode: o
    rechunk:
      time: -1


biasadjust:
  dtr:
    dask: &dask_ba
      n_workers: 6
      threads_per_worker: 3
      memory_limit: "4GB"
    sim_inputs: &sim_inputs
      type: simulation
      processing_level: regridded
    ref_input: &ref_input
      type: reconstruction
      processing_level: extracted
    xscen_train:
      period: *ref_period
      method: DetrendedQuantileMapping
      group:
        group: time.dayofyear
        window: 31
      xclim_train_args:
        kind: "*"
        nquantiles: 50
      #maximal_calendar:
      #adapt_freq:
      #jitter_under:
      #jitter_over:
      #align_on:
    xscen_adjust:
      periods: *sim_period
      xclim_adjust_args:
        detrend:
          LoessDetrend:
            f: 0.2
            niter: 1
            d: 0
            weights: tricube
        interp: nearest
        extrapolation: constant
      bias_adjust_institution: &b_a_inst
        Ouranos
      bias_adjust_project: &b_a_pro
        template1
      #moving_yearly_window:
      #align_on:
    save: *save_time_-1
  tasmax:
    dask: *dask_ba
    sim_inputs: *sim_inputs
    ref_input: *ref_input
    xscen_train:
      period: *ref_period
      method: DetrendedQuantileMapping
      group:
        group: time.dayofyear
        window: 31
      xclim_train_args:
        kind: "+"
        nquantiles: 50
    xscen_adjust:
      periods: *sim_period
      xclim_adjust_args:
        detrend:
          LoessDetrend:
            f: 0.2
            niter: 1
            d: 0
            weights: tricube
        interp: nearest
        extrapolation: constant
      bias_adjust_institution: *b_a_inst
      bias_adjust_project: *b_a_pro
    save: *save_time_-1
  pr:
    dask: *dask_ba
    sim_inputs: *sim_inputs
    ref_input: *ref_input
    xscen_train:
      period: *ref_period
      method: DetrendedQuantileMapping
      group:
        group: time.dayofyear
        window: 31
      jitter_under:
        thresh: 0.05 mm d-1
      xclim_train_args:
        kind: "*"
        nquantiles: 50
    xscen_adjust:
      periods: *sim_period
      xclim_adjust_args:
        detrend:
          LoessDetrend:
            f: 0.2
            niter: 1
            d: 0
            weights: tricube
        interp: nearest
        extrapolation: constant
      bias_adjust_institution: *b_a_inst
      bias_adjust_project: *b_a_pro
    save: *save_time_-1


cleanup:
  dask:
    n_workers: 4
    threads_per_worker: 3
    memory_limit: "6GB"
  search_data_catalogs:
    variables_and_freqs:
      tasmax: D
      tasmin: D
      pr: D
    allow_conversion: True
    allow_resampling: False
    other_search_criteria:
      processing_level: biasadjusted
  xscen_clean_up:
    to_level: cleaned
    maybe_unstack_dict:
      stack_drop_nans: *stack
      rechunk:
        lat: 15
        lon: 15
        time: -1
    variables_and_units: &units
      tasmax: degC
      tasmin: degC
      pr: mm d-1
    convert_calendar_kwargs:
      target: standard
      align_on: random
    missing_by_var:
      tasmax: interpolate
      tasmin: interpolate
      pr: [ 0 ]
    #round_var:
    #common_attrs_only:
    #common_attrs_open_kwargs:
    #attrs_to_remove:
    #remove_all_attrs_except:
    #add_attrs:
    #change_attr_prefix:
    #to_level: Optional[str] = None)
  save:
    mode: o
    encoding:
      tasmax:
        dtype: float32
      tasmin:
        dtype: float32
      pr:
        dtype: float32


rechunk:
  dask:
    n_workers: 3
    threads_per_worker: 5
    memory_limit: "6GB"
  inputs:
    processing_level: cleaned
  xscen_rechunk:
    worker_mem: 2GB
    chunks_over_dim:
      lat: 3
      lon: 3
      time: 4year
    overwrite: True
    #chunks_over_var:


diagnostics:
  dask:
    n_workers: 3
    threads_per_worker: 5
    memory_limit: "5GB"
  health_checks:
    freq: D
    calendar: standard
    variables_and_units:
      tasmax: degC
      tasmin: degC
      pr: mm d-1
    cfchecks:
      tasmax: {'cfcheck_from_name': {}}
      tasmin: {'cfcheck_from_name': {}}
      pr: {'cfcheck_from_name': {}}
    flags:
      tasmax:  # `None` flags means that it will use xclim's default flags for the given variable
      tasmin:
      pr:
    # structure
    # start_date
    # end_date
    # missing
    # flag_kwargs
    # return_flags
    # raise_on  # Since we don't raise on anything, the function will print warnings instead
  kind:
    reference:
      inputs:
        processing_level: extracted
        type: reconstruction
      properties_and_measures:
        period: *ref_period
        unstack: *stack
        change_units_arg: *units
        to_level_prop: diag-properties-ref
        #rechunk:
        #to_level_meas:
      save:
        mode: o
        rechunk:
          lat: -1
          lon: -1
    simulation:
      inputs:
        processing_level: regridded
        type: simulation
      dref_for_measure:
        processing_level: diag-properties-ref
      properties_and_measures:
        period: *ref_period
        unstack: *stack
        change_units_arg: *units
        to_level_prop: diag-properties-sim
        to_level_meas: diag-measures-sim
      save:
        mode: o
        rechunk:
          lat: -1
          lon: -1
    scenario:
      inputs:
        processing_level: cleaned
        type: simulation
      dref_for_measure:
        processing_level: diag-properties-ref
      properties_and_measures:
        period: *ref_period
        unstack: False
        to_level_prop: diag-properties-scen
        to_level_meas: diag-measures-scen
      save:
        mode: o
        rechunk:
          lat: -1
          lon: -1
  measures_heatmap: {} # automatically passed to the function
    #to_level:
  measures_improvement: {}   # automatically passed to the function
    #to_level:

indicators:
  dask:
    n_workers: 8
    threads_per_worker: 5
    memory_limit: "2GB"
  inputs:
    processing_level: final
  compute_indicators: {} # automatically passed to the function
    #periods:
    #to_level:
  save: *save_time_-1


aggregate:
  dask:
    n_workers: 4
    threads_per_worker: 4
    memory_limit: "6GB"
  input:
    clim:
      processing_level: indicators
    delta:
      processing_level: climatology
  climatological_mean: # automatically passed to the function
    window: 30
    interval: 10
    periods: [['1951', '2100']]
    to_level: climatology
    #min_periods:
  compute_deltas: # automatically passed to the function
    kind: "+"
    reference_horizon: "1991-2020"
    to_level: 'delta'
    #rename_variables:
  save:
    mode: 'o'


ensembles:
  dask:
    n_workers: 3
    threads_per_worker: 5
    memory_limit: "5GB"
  processing_levels:
    - indicators
    - climatology
    - delta
  ensemble_stats: # automatically passed to the function
    statistics:
      ensemble_percentiles:
        split: False
    common_attrs_only: True
    #create_kwargs:
    #weights:
    #to_level:
  save:
    mode: o


# General Arguments

project: # argument to create the project
  name: Template 1 - basic_workflow_with_config
  version: 1.0.0
  description: Template for xscen workflow
  id: t1

scripting: # send an email when code fails or succeed
  subject: Template 1 - basic_workflow_with_config
  send_mail_on_exit:
    msg_err: Something went wrong!
    on_error_only: True


dask: # general dask arguments
  array.slicing.split_large_chunks: False


logging: # general logging args
  formatters:
    default:
      format: '%(asctime)s %(levelname)-8s %(name)-15s %(message)s'
      datefmt: '%Y-%m-%d %H:%M:%S'
  handlers:
    console:
      class : logging.StreamHandler
      formatter: default
      level : INFO
#    file:
#      class: logging.FileHandler
#      formatter: default
#      level : DEBUG
  loggers:
    xscen:
      propagate: False
      level: INFO
      handlers: [console] # [file, console] could also be used to write the log to a file


to_dataset_dict: # parameters to open datasets
  xarray_open_kwargs:
    decode_timedelta: False
