
@article{deque_frequency_2007,
	series = {Extreme {Climatic} {Events}},
	title = {Frequency of precipitation and temperature extremes over {France} in an anthropogenic scenario: {Model} results and statistical correction according to observed values},
	volume = {57},
	issn = {0921-8181},
	shorttitle = {Frequency of precipitation and temperature extremes over {France} in an anthropogenic scenario},
	url = {https://www.sciencedirect.com/science/article/pii/S0921818106002748},
	doi = {10.1016/j.gloplacha.2006.11.030},
	abstract = {Météo-France atmospheric model ARPEGE/Climate has been used to simulate present climate (1961–1990) and a possible future climate (2071–2100) through two ensembles of three 30-year numerical experiments. In the scenario experiment, the greenhouse gas and aerosol concentrations are prescribed by the so-called SRES-A2 hypotheses, whereas the sea surface temperature and sea ice extent come from an earlier ocean–atmosphere coupled simulation. The model covers the whole globe, with a variable resolution reaching 50 to 60 km over France. Model responses on daily minimum and maximum temperature and precipitation are analyzed over France. The distribution of daily values is compared with observed data from the French climatological network. The extreme cold temperatures and summer heavy precipitations are underestimated by the model. A correction technique is proposed in order to adjust the simulated values according to the observed ones. This process is applied to both reference and scenario simulation. Synthetic indices of extreme events are calculated with corrected simulations. The number of heavy rain ({\textgreater}10 mm) days increases by one quarter in winter. The maximum length of summer dry episodes increases by one half in summer. The number of heat wave days is multiplied by 10. The response in precipitation is less when only the change in the mean is considered. Such a corrected simulation is useful to feed impact models which are sensitive to threshold values, but the correction does not reduce, and may enhance in some cases, the uncertainty about the climate projections. Using several models and scenarios is the appropriate technique to deal with uncertainty.},
	language = {en},
	number = {1},
	urldate = {2022-07-29},
	journal = {Global and Planetary Change},
	author = {Déqué, Michel},
	month = may,
	year = {2007},
	keywords = {extreme values, numerical simulation, regional climate, scenario},
	pages = {16--26},
}

@article{cannon_bias_2015,
	title = {Bias {Correction} of {GCM} {Precipitation} by {Quantile} {Mapping}: {How} {Well} {Do} {Methods} {Preserve} {Changes} in {Quantiles} and {Extremes}?},
	volume = {28},
	issn = {0894-8755, 1520-0442},
	shorttitle = {Bias {Correction} of {GCM} {Precipitation} by {Quantile} {Mapping}},
	url = {https://journals.ametsoc.org/view/journals/clim/28/17/jcli-d-14-00754.1.xml},
	doi = {10.1175/JCLI-D-14-00754.1},
	abstract = {Abstract Quantile mapping bias correction algorithms are commonly used to correct systematic distributional biases in precipitation outputs from climate models. Although they are effective at removing historical biases relative to observations, it has been found that quantile mapping can artificially corrupt future model-projected trends. Previous studies on the modification of precipitation trends by quantile mapping have focused on mean quantities, with less attention paid to extremes. This article investigates the extent to which quantile mapping algorithms modify global climate model (GCM) trends in mean precipitation and precipitation extremes indices. First, a bias correction algorithm, quantile delta mapping (QDM), that explicitly preserves relative changes in precipitation quantiles is presented. QDM is compared on synthetic data with detrended quantile mapping (DQM), which is designed to preserve trends in the mean, and with standard quantile mapping (QM). Next, methods are applied to phase 5 of the Coupled Model Intercomparison Project (CMIP5) daily precipitation projections over Canada. Performance is assessed based on precipitation extremes indices and results from a generalized extreme value analysis applied to annual precipitation maxima. QM can inflate the magnitude of relative trends in precipitation extremes with respect to the raw GCM, often substantially, as compared to DQM and especially QDM. The degree of corruption in the GCM trends by QM is particularly large for changes in long period return values. By the 2080s, relative changes in excess of +500\% with respect to historical conditions are noted at some locations for 20-yr return values, with maximum changes by DQM and QDM nearing +240\% and +140\%, respectively, whereas raw GCM changes are never projected to exceed +120\%.},
	language = {EN},
	number = {17},
	urldate = {2022-07-29},
	journal = {Journal of Climate},
	author = {Cannon, Alex J. and Sobie, Stephen R. and Murdock, Trevor Q.},
	month = sep,
	year = {2015},
	pages = {6938--6959},
}

@misc{cannon_mbc_2020,
	title = {{MBC}: {Multivariate} {Bias} {Correction} of {Climate} {Model} {Outputs}},
	copyright = {GPL-2},
	shorttitle = {{MBC}},
	url = {https://CRAN.R-project.org/package=MBC},
	abstract = {Calibrate and apply multivariate bias correction algorithms for climate model simulations of multiple climate variables. Three methods described by Cannon (2016) {\textless}doi:10.1175/JCLI-D-15-0679.1{\textgreater} and Cannon (2018) {\textless}doi:10.1007/s00382-017-3580-6{\textgreater} are implemented — (i) MBC Pearson correlation (MBCp), (ii) MBC rank correlation (MBCr), and (iii) MBC N-dimensional PDF transform (MBCn) — as is the Rank Resampling for Distributions and Dependences (R2D2) method.},
	urldate = {2022-07-29},
	author = {Cannon, Alex J.},
	month = oct,
	year = {2020},
	keywords = {Hydrology},
}


@article{roy_extremeprecip_2023,
	title = {Climate scenarios of extreme precipitation using a combination of parametric and non-parametric bias correction methods in the province of Québec},
	url = {https://www.tandfonline.com/doi/full/10.1080/07011784.2023.2220682},
	doi = {10.1080/07011784.2023.2220682},
	language = {English},
	journal = {Canadian Water Resources Journal},
	author = {Roy, Philippe and Rondeau-Genesse, Gabriel and Jalbert, Jonathan and Fournier, Élyse},
	month = {june},
	year = {2023},
}

@misc{roy_juliaclimateclimatetoolsjl_2021,
	title = {{JuliaClimate}/{ClimateTools}.jl: v0.23.1},
	shorttitle = {{JuliaClimate}/{ClimateTools}.jl},
	url = {https://zenodo.org/record/5399172},
	abstract = {ClimateTools v0.23.1 Diff since v0.23.0 Closed issues: possible test failure in upcoming Julia version 1.5 (\#148) Merged pull requests: CompatHelper: bump compat for "DataFrames" to "1.0" (\#191) (@github-actions[bot]) CompatHelper: bump compat for "GeoStats" to "0.25" (\#193) (@github-actions[bot]) CompatHelper: bump compat for "Reexport" to "1" (\#194) (@github-actions[bot]) CompatHelper: bump compat for Reexport to 1, (keep existing compat) (\#196) (@github-actions[bot]) CompatHelper: bump compat for Interpolations to 0.13, (keep existing compat) (\#197) (@github-actions[bot]) CompatHelper: bump compat for NCDatasets to 0.11, (keep existing compat) (\#198) (@github-actions[bot]) CompatHelper: bump compat for GeoStats to 0.26, (keep existing compat) (\#199) (@github-actions[bot]) CompatHelper: bump compat for NetCDF to 0.11, (keep existing compat) (\#201) (@github-actions[bot]) CompatHelper: bump compat for ClimateBase to 0.13, (keep existing compat) (\#202) (@github-actions[bot]) CompatHelper: bump compat for Distances to 0.10, (keep existing compat) (\#204) (@github-actions[bot]) CompatHelper: bump compat for Shapefile to 0.7, (keep existing compat) (\#205) (@github-actions[bot]) fix for extreme bug (\#206) (@Balinus)},
	urldate = {2022-07-29},
	publisher = {Zenodo},
	author = {Roy, Philippe and Smith, Trevor James and Kelman, Tony and Nolet-Gravel, Éloïse and Saba, Elliot and Thomet, Fidel and TagBot, Julia and Forget, Gael},
	month = sep,
	year = {2021},
	doi = {10.5281/zenodo.5399172},
}

@article{schmidli_downscaling_2006,
	title = {Downscaling from {GCM} precipitation: a benchmark for dynamical and statistical downscaling methods},
	volume = {26},
	issn = {1097-0088},
	shorttitle = {Downscaling from {GCM} precipitation},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.1287},
	doi = {10.1002/joc.1287},
	abstract = {A precipitation downscaling method is presented using precipitation from a general circulation model (GCM) as predictor. The method extends a previous method from monthly to daily temporal resolution. The simplest form of the method corrects for biases in wet-day frequency and intensity. A more sophisticated variant also takes account of flow-dependent biases in the GCM. The method is flexible and simple to implement. It is proposed here as a correction of GCM output for applications where sophisticated methods are not available, or as a benchmark for the evaluation of other downscaling methods. Applied to output from reanalyses (ECMWF, NCEP) in the region of the European Alps, the method is capable of reducing large biases in the precipitation frequency distribution, even for high quantiles. The two variants exhibit similar performances, but the ideal choice of method can depend on the GCM/reanalysis and it is recommended to test the methods in each case. Limitations of the method are found in small areas with unresolved topographic detail that influence higher-order statistics (e.g. high quantiles). When used as benchmark for three regional climate models (RCMs), the corrected reanalysis and the RCMs perform similarly in many regions, but the added value of the latter is evident for high quantiles in some small regions. Copyright © 2006 Royal Meteorological Society.},
	language = {en},
	number = {5},
	urldate = {2022-07-29},
	journal = {International Journal of Climatology},
	author = {Schmidli, Jürg and Frei, Christoph and Vidale, Pier Luigi},
	year = {2006},
	keywords = {European alps, precipitation statistics, reanalysis, regional climate model, statistical downscaling},
	pages = {679--689},
}

@article{hnilica_multisite_2017,
	title = {Multisite bias correction of precipitation data from regional climate models},
	volume = {37},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.4890},
	doi = {10.1002/joc.4890},
	abstract = {The characteristics of precipitation in regional climate model simulations deviate considerably from those of the observed data; therefore, bias correction is a standard part of most climate change impact assessment studies. The standard approach is that the corrections are calibrated and applied separately for individual spatial points and meteorological variables. For this reason, the correlation and covariance structures of the observed and corrected data differ, although the individual observed and corrected data sets correspond well in their statistical indicators. This inconsistency may affect impact studies using corrected simulations. This study presents a new approach to the bias correction utilizing principal components in combination with quantile mapping, which allows for the correction of multivariate data sets. The proposed procedure significantly reduces the bias in covariance and correlation structures, as well as that in the distribution of individual variables. This is in contrast to standard quantile mapping, which only corrects the individual distributions, and leaves the dependence structure biased.},
	language = {en},
	number = {6},
	urldate = {2022-07-29},
	journal = {International Journal of Climatology},
	author = {Hnilica, Jan and Hanel, Martin and Puš, Vladimír},
	year = {2017},
	keywords = {bias correction, correlation, covariance, multisite correction, multivariate data, precipitation, principal components, regional climate model},
	pages = {2934--2946},
}

@article{cannon_multivariate_2018,
	title = {Multivariate quantile mapping bias correction: an {N}-dimensional probability density function transform for climate model simulations of multiple variables},
	volume = {50},
	issn = {1432-0894},
	shorttitle = {Multivariate quantile mapping bias correction},
	url = {https://doi.org/10.1007/s00382-017-3580-6},
	doi = {10.1007/s00382-017-3580-6},
	abstract = {Most bias correction algorithms used in climatology, for example quantile mapping, are applied to univariate time series. They neglect the dependence between different variables. Those that are multivariate often correct only limited measures of joint dependence, such as Pearson or Spearman rank correlation. Here, an image processing technique designed to transfer colour information from one image to another—the N-dimensional probability density function transform—is adapted for use as a multivariate bias correction algorithm (MBCn) for climate model projections/predictions of multiple climate variables. MBCn is a multivariate generalization of quantile mapping that transfers all aspects of an observed continuous multivariate distribution to the corresponding multivariate distribution of variables from a climate model. When applied to climate model projections, changes in quantiles of each variable between the historical and projection period are also preserved. The MBCn algorithm is demonstrated on three case studies. First, the method is applied to an image processing example with characteristics that mimic a climate projection problem. Second, MBCn is used to correct a suite of 3-hourly surface meteorological variables from the Canadian Centre for Climate Modelling and Analysis Regional Climate Model (CanRCM4) across a North American domain. Components of the Canadian Forest Fire Weather Index (FWI) System, a complicated set of multivariate indices that characterizes the risk of wildfire, are then calculated and verified against observed values. Third, MBCn is used to correct biases in the spatial dependence structure of CanRCM4 precipitation fields. Results are compared against a univariate quantile mapping algorithm, which neglects the dependence between variables, and two multivariate bias correction algorithms, each of which corrects a different form of inter-variable correlation structure. MBCn outperforms these alternatives, often by a large margin, particularly for annual maxima of the FWI distribution and spatiotemporal autocorrelation of precipitation fields.},
	language = {en},
	number = {1},
	urldate = {2022-07-29},
	journal = {Climate Dynamics},
	author = {Cannon, Alex J.},
	month = jan,
	year = {2018},
	keywords = {Bias correction, Climate model, Fire weather, Model output statistics, Multivariate, Post-processing, Precipitation, Quantile mapping},
	pages = {31--49},
}

@inproceedings{pitie_n-dimensional_2005,
	title = {N-dimensional probability density function transfer and its application to color transfer},
	volume = {2},
	doi = {10.1109/ICCV.2005.166},
	abstract = {This article proposes an original method to estimate a continuous transformation that maps one N-dimensional distribution to another. The method is iterative, non-linear, and is shown to converge. Only 1D marginal distribution is used in the estimation process, hence involving low computation costs. As an illustration this mapping is applied to color transfer between two images of different contents. The paper also serves as a central focal point for collecting together the research activity in this area and relating it to the important problem of automated color grading},
	language = {en},
	booktitle = {Tenth {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV}'05) {Volume} 1},
	author = {Pitie, F. and Kokaram, A.C. and Dahyot, R.},
	month = oct,
	year = {2005},
	keywords = {Color, Computational efficiency, Density functional theory, Distributed computing, Educational institutions, Image converters, Iterative methods, Rendering (computer graphics), Statistical distributions, Statistics},
	pages = {1434--1439 Vol. 2},
}

@article{szekely_testing_2004,
	title = {Testing for equal distributions in high dimension},
	volume = {5},
	abstract = {We propose a new nonparametric test for equality of two or more multivariate distributions based on Euclidean distance between sample elements. Several consistent tests for comparing multivariate distribu-tions can be developed from the underlying theoretical results. The test procedure for the multisample problem is developed and applied for testing the composite hypothesis of equal distributions, when dis-tributions are unspecified. The proposed test is universally consistent against all fixed alternatives (not necessarily continuous) with finite second moments. The test is implemented by conditioning on the pooled sample to obtain an approximate permutation test, which is distribution free. Our Monte Carlo power study suggests that the new test may be much more sensitive than tests based on nearest neighbors against several classes of alternatives, and performs particularly well in high dimension. Computational complexity of our test procedure is independent of dimension and number of populations sampled. The test is applied in a high dimensional problem, testing microarray data from cancer samples.},
	journal = {InterStat},
	author = {Szekely, Gabor and Rizzo, Maria},
	month = nov,
	year = {2004},
}

@misc{mezzadri_how_2007,
	title = {How to generate random matrices from the classical compact groups},
	url = {https://arxiv.org/abs/math-ph/0609050},
	doi = {10.48550/arXiv.math-ph/0609050},
	abstract = {We discuss how to generate random unitary matrices from the classical compact groups U(N), O(N) and USp(N) with probability distributions given by the respective invariant measures. The algorithm is straightforward to implement using standard linear algebra packages. This approach extends to the Dyson circular ensembles too. This article is based on a lecture given by the author at the summer school on Number Theory and Random Matrix Theory held at the University of Rochester in June 2006. The exposition is addressed to a general mathematical audience.},
	urldate = {2022-11-16},
	publisher = {arXiv},
	author = {Mezzadri, Francesco},
	month = feb,
	year = {2007},
	keywords = {1502,15A52, 65F25, Mathematical Physics, Mathematics - Numerical Analysis},
}

@article{hyndman_sample_1996,
	title = {Sample {Quantiles} in {Statistical} {Packages}},
	volume = {50},
	issn = {0003-1305},
	url = {https://www.tandfonline.com/doi/abs/10.1080/00031305.1996.10473566},
	doi = {10.1080/00031305.1996.10473566},
	abstract = {There are a large number of different definitions used for sample quantiles in statistical computer packages. Often within the same package one definition will be used to compute a quantile explicitly, while other definitions may be used when producing a boxplot, a probability plot, or a QQ plot. We compare the most commonly implemented sample quantile definitions by writing them in a common notation and investigating their motivation and some of their properties. We argue that there is a need to adopt a standard definition for sample quantiles so that the same answers are produced by different packages and within each package. We conclude by recommending that the median-unbiased estimator be used because it has most of the desirable properties of a quantile estimator and can be defined independently of the underlying distribution.},
	number = {4},
	urldate = {2022-08-03},
	journal = {The American Statistician},
	author = {Hyndman, Rob J. and Fan, Yanan},
	month = nov,
	year = {1996},
	keywords = {Percentiles, Quartiles, Sample quantiles, Statistical computer packages},
	pages = {361--365},
}

@article{cleveland_robust_1979,
	title = {Robust {Locally} {Weighted} {Regression} and {Smoothing} {Scatterplots}},
	volume = {74},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1979.10481038},
	doi = {10.1080/01621459.1979.10481038},
	abstract = {The visual information on a scatterplot can be greatly enhanced, with little additional cost, by computing and plotting smoothed points. Robust locally weighted regression is a method for smoothing a scatterplot, (x i , y i ), i = 1, …, n, in which the fitted value at z k is the value of a polynomial fit to the data using weighted least squares, where the weight for (x i , y i ) is large if x i is close to x k and small if it is not. A robust fitting procedure is used that guards against deviant points distorting the smoothed points. Visual, computational, and statistical issues of robust locally weighted regression are discussed. Several examples, including data on lead intoxication, are used to illustrate the methodology.},
	number = {368},
	urldate = {2022-07-29},
	journal = {Journal of the American Statistical Association},
	author = {Cleveland, William S.},
	month = dec,
	year = {1979},
	keywords = {Graphics, Nonparametric regression, Robust estimation, Scatterplots, Smoothing},
	pages = {829--836},
}

@misc{gramfort_lowess_2015,
	title = {{LOWESS} : {Locally} weighted regression},
	copyright = {BSD 3-Clause},
	shorttitle = {{LOWESS}},
	url = {https://gist.github.com/agramfort/850437},
	abstract = {LOWESS : Locally weighted regression. GitHub Gist: instantly share code, notes, and snippets.},
	urldate = {2022-08-05},
	author = {Gramfort, Alexandre},
	month = oct,
	year = {2015},
}


@article{themesl_empirical-statistical_2012,
	title = {Empirical-statistical downscaling and error correction of regional climate models and its impact on the climate change signal},
	volume = {112},
	issn = {1573-1480},
	url = {https://doi.org/10.1007/s10584-011-0224-4},
	doi = {10.1007/s10584-011-0224-4},
	abstract = {Realizing the error characteristics of regional climate models (RCMs) and the consequent limitations in their direct utilization in climate change impact research, this study analyzes a quantile-based empirical-statistical error correction method (quantile mapping, QM) for RCMs in the context of climate change. In particular the success of QM in mitigating systematic RCM errors, its ability to generate “new extremes” (values outside the calibration range), and its impact on the climate change signal (CCS) are investigated. In a cross-validation framework based on a RCM control simulation over Europe, QM reduces the bias of daily mean, minimum, and maximum temperature, precipitation amount, and derived indices of extremes by about one order of magnitude and strongly improves the shapes of the related frequency distributions. In addition, a simple extrapolation of the error correction function enables QM to reproduce “new extremes” without deterioration and mostly with improvement of the original RCM quality. QM only moderately modifies the CCS of the corrected parameters. The changes are related to trends in the scenarios and magnitude-dependent error characteristics. Additionally, QM has a large impact on CCSs of non-linearly derived indices of extremes, such as threshold indices.},
	language = {en},
	number = {2},
	urldate = {2022-07-29},
	journal = {Climatic Change},
	author = {Themeßl, Matthias Jakob and Gobiet, Andreas and Heinrich, Georg},
	month = may,
	year = {2012},
	keywords = {Climate Change Signal, Pacific Decadal Oscillation, Precipitation Amount, Quantile Mapping, Regional Climate Model},
	pages = {449--468},
}


@article{baringhaus_new_2004,
	title = {On a new multivariate two-sample test},
	volume = {88},
	issn = {0047-259X},
	url = {https://www.sciencedirect.com/science/article/pii/S0047259X03000794},
	doi = {10.1016/S0047-259X(03)00079-4},
	abstract = {In this paper we propose a new test for the multivariate two-sample problem. The test statistic is the difference of the sum of all the Euclidean interpoint distances between the random variables from the two different samples and one-half of the two corresponding sums of distances of the variables within the same sample. The asymptotic null distribution of the test statistic is derived using the projection method and shown to be the limit of the bootstrap distribution. A simulation study includes the comparison of univariate and multivariate normal distributions for location and dispersion alternatives. For normal location alternatives the new test is shown to have power similar to that of the t- and T2-Test.},
	language = {en},
	number = {1},
	urldate = {2022-07-29},
	journal = {Journal of Multivariate Analysis},
	author = {Baringhaus, L. and Franz, C.},
	month = jan,
	year = {2004},
	keywords = {Bootstrapping, Cramér test, Multivariate two-sample test, Orthogonal invariance, Projection method},
	pages = {190--206},
}
@article{alavoine_distinct_2022,
	title = {The distinct problems of physical inconsistency and of multivariate bias involved in the statistical adjustment of climate simulations},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.7878},
	doi = {10.1002/joc.7878},
	abstract = {Bias adjustment of numerical climate model simulations involves several arguments wherein the notion of physical inconsistency is referred to, either for rejecting the legitimacy of bias adjustment in general or for justifying the necessity of sophisticated multivariate techniques. However, this notion is often mishandled, in part because the literature generally proceeds without defining it. In this context, the central objective of this study is to clarify and illustrate the distinction between physical inconsistency and multivariate bias, by investigating the effect of bias adjustment on two different kinds of intervariable relationships, namely a physical constraint expected to hold at every step of a time series and statistical properties that emerge with potential bias over a climatic timescale. To this end, 18 alternative bias adjustment techniques are applied on 10 climate simulations at 12 sites over North America. Adjusted variables are temperature, pressure, relative humidity and specific humidity, linked by a thermodynamic constraint. The analysis suggests on the one hand that a clear instance of potential physical inconsistency can be avoided with either a univariate or a multivariate technique, if and only if the bias adjustment strategy explicitly considers the physical constraint to be preserved. On the other hand, it also suggests that sophisticated multivariate techniques alone are not complete adjustment strategies in presence of a physical constraint, as they cannot replace its explicit consideration. By involving common bias adjustment procedures with likely effects on diverse basic statistical properties, this study may also help guide climate information users in the determination of adequate bias adjustment strategies for their research purposes.},
	language = {en},
	urldate = {2022-11-16},
	journal = {International Journal of Climatology},
	author = {Alavoine, Mégane and Grenier, Patrick},
	month = sep,
	year = {2022},
	keywords = {bias adjustment techniques, climate simulations, multivariate biases, physical relationships},
	pages = {1--23},
}

@article{francois_multivariate_2020,
	title = {Multivariate bias corrections of climate simulations: which benefits for which losses?},
	volume = {11},
	issn = {2190-4979},
	shorttitle = {Multivariate bias corrections of climate simulations},
	url = {https://esd.copernicus.org/articles/11/537/2020/},
	doi = {10.5194/esd-11-537-2020},
	language = {English},
	number = {2},
	urldate = {2022-04-27},
	journal = {Earth System Dynamics},
	author = {François, Bastien and Vrac, Mathieu and Cannon, Alex J. and Robin, Yoann and Allard, Denis},
	month = jun,
	year = {2020},
	pages = {537--562},
}

@misc{jalbert_extreme_2022,
	title = {Extreme value analysis package for {Julia}.},
	url = {https://github.com/jojal5/Extremes.jl},
	abstract = {Extreme value analysis package for Julia},
	urldate = {2022-07-29},
	author = {Jalbert, Jonathan},
	month = jun,
	year = {2022},
}


@book{coles_introduction_2001,
	address = {London, UK},
	series = {Springer {Series} in {Statistics}},
	title = {An {Introduction} to {Statistical} {Modeling} of {Extreme} {Values}},
	isbn = {978-1-85233-459-8},
	url = {https://link.springer.com/book/10.1007/978-1-4471-3675-0},
	abstract = {Directly oriented towards real practical application, this book develops both the basic theoretical framework of extreme value models and the statistical inferential techniques for using these models in practice. Intended for statisticians and non-statisticians alike, the theoretical treatment is elementary, with heuristics often replacing detailed mathematical proof. Most aspects of extreme modeling techniques are covered, including historical techniques (still widely used) and contemporary techniques based on point process models. A wide range of worked examples, using genuine datasets, illustrate the various modeling procedures and a concluding chapter provides a brief introduction to a number of more advanced topics, including Bayesian inference and spatial extremes. All the computations are carried out using S-PLUS, and the corresponding datasets and functions are available via the Internet for readers to recreate examples for themselves. An essential reference for students and researchers in statistics and disciplines such as engineering, finance and environmental science, this book will also appeal to practitioners looking for practical help in solving real problems. Stuart Coles is Reader in Statistics at the University of Bristol, UK, having previously lectured at the universities of Nottingham and Lancaster. In 1992 he was the first recipient of the Royal Statistical Society's research prize. He has published widely in the statistical literature, principally in the area of extreme value modeling.},
	language = {en},
	urldate = {2022-07-29},
	publisher = {Springer-Verlag},
	author = {Coles, Stuart},
	month = aug,
	year = {2001},
	keywords = {Mathematics / Probability \& Statistics / General, Mathematics / Probability \& Statistics / Stochastic Processes, Medical / Biostatistics},
}

@book{cohen_parameter_2019,
	title = {Parameter {Estimation} in {Reliability} and {Life} {Span} {Models}},
	isbn = {978-0-367-40334-8},
	abstract = {Offers an applications-oriented treatment of parameter estimation from both complete and censored samples; contains notations, simplified formats for estimates, graphical techniques, and numerous tables and charts allowing users to calculate estimates and analyze sample data quickly and easily. Furnishing numerous practical examples, this resource serves as a handy reference for statisticians, biometricians, medical researchers, operations research and quality control practitioners, reliability and design engineers, and all others involved in the analysis of sample data from skewed distributions, as well as a text for senior undergraduate and graduate students in statistics, quality control, operations research, mathematics and biometry courses.},
	publisher = {CRC Press},
	author = {Cohen, A Clifford and Whitten, Betty Jones},
	month = sep,
	year = {2019},
}

@article{thom_1958,
    title = {A Note on the Gamma Distribution},
    author = {Thom, H. C. S.},
    year = {1958},
    journal = {Monthly Weather Review},
    volume = {86},
    number = {4},
    pages = {117--122},
    publisher = {{American Meteorological Society}},
    issn = {1520-0493, 0027-0644},
    doi = {10.1175/1520-0493(1958)086<0117:ANOTGD>2.0.CO;2},
    abstract = {Abstract The general properties of the gamma distribution, which has several applications in meteorology, are discussed. A short review of the general properties of good statistical estimators is given. This is applied to the gamma distribution to show that the maximum likelihood estimators are jointly sufficient. A new, simple approximation of the likelihood solutions is given, and the efficiency of the fitting procedure is computed.},
    chapter = {Monthly Weather Review},
}

@article{muralidhar_1992,
    title = {A {{Simple Minimum}}-{{Bias Percentile Estimator}} of the {{Location Parameter}} for the {{Gamma}}, {{Weibull}}, and {{Log}}-{{Normal Distributions}}},
    author = {Muralidhar, Krishnamurty and Zanakis, Stelios H.},
    year = {1992},
    month = jul,
    journal = {Decision Sciences},
    volume = {23},
    number = {4},
    pages = {862--879},
    issn = {0011-7315, 1540-5915},
    doi = {10.1111/j.1540-5915.1992.tb00423.x}
}

@article{cooke_1979,
    title = {Statistical Inference for Bounds of Random Variables},
    author = {Cooke, Peter},
    year = {1979},
    journal = {Biometrika},
    volume = {66},
    number = {2},
    pages = {367--374},
    issn = {0006-3444, 1464-3510},
    doi = {10.1093/biomet/66.2.367}
}

@article{hoffmann_meteorologically_2012,
	title = {Meteorologically consistent bias correction of climate time series for agricultural models},
	volume = {110},
	issn = {1434-4483},
	url = {https://doi.org/10.1007/s00704-012-0618-x},
	doi = {10.1007/s00704-012-0618-x},
	abstract = {Conventional bias correction of simulated climate time series for impact models is done separately for climate variables and hence leads to inconsistencies between them. However, agricultural models mostly use several variables, and meteorological consistency is essential. The present work points out meteorological inconsistency due to quantile mapping and describes a new method of consistent bias correction by an optimization approach. Time series of hourly precipitation and global radiation from the regional model REMO5.7 (Run UBA C20/A1B\_1) were corrected with site observations from the German Meteorological Service. The results urge to check conventionally corrected series for consistency before using them for multidimensional models. Here, quantile mapping resulted in underestimation of diffuse radiation at hours with precipitation. This deficit was minimized by the developed procedure.},
	language = {en},
	number = {1},
	urldate = {2022-08-03},
	journal = {Theoretical and Applied Climatology},
	author = {Hoffmann, Holger and Rath, Thomas},
	month = oct,
	year = {2012},
	keywords = {Bias Correction, Diffuse Radiation, Global Radiation, Quantile Mapping, Simulated Time Series},
	pages = {129--141},
}

@article{thrasher_technical_2012,
	title = {Technical {Note}: {Bias} correcting climate model simulated daily temperature extremes with quantile mapping},
	volume = {16},
	issn = {1027-5606},
	shorttitle = {Technical {Note}},
	url = {https://hess.copernicus.org/articles/16/3309/2012/},
	doi = {10.5194/hess-16-3309-2012},
	abstract = {{\textless}p{\textgreater}{\textless}strong class="journal-contentHeaderColor"{\textgreater}Abstract.{\textless}/strong{\textgreater} When applying a quantile mapping-based bias correction to daily temperature extremes simulated by a global climate model (GCM), the transformed values of maximum and minimum temperatures are changed, and the diurnal temperature range (DTR) can become physically unrealistic. While causes are not thoroughly explored, there is a strong relationship between GCM biases in snow albedo feedback during snowmelt and bias correction resulting in unrealistic DTR values. We propose a technique to bias correct DTR, based on comparing observations and GCM historic simulations, and combine that with either bias correcting daily maximum temperatures and calculating daily minimum temperatures or vice versa. By basing the bias correction on a base period of 1961–1980 and validating it during a test period of 1981–1999, we show that bias correcting DTR and maximum daily temperature can produce more accurate estimations of daily temperature extremes while avoiding the pathological cases of unrealistic DTR values.{\textless}/p{\textgreater}},
	language = {English},
	number = {9},
	urldate = {2022-08-03},
	journal = {Hydrology and Earth System Sciences},
	author = {Thrasher, B. and Maurer, E. P. and McKellar, C. and Duffy, P. B.},
	month = sep,
	year = {2012},
	note = {Publisher: Copernicus GmbH},
	pages = {3309--3314},
}

@article{grenier_two_2018,
	title = {Two {Types} of {Physical} {Inconsistency} to {Avoid} with {Univariate} {Quantile} {Mapping}: {A} {Case} {Study} over {North} {America} {Concerning} {Relative} {Humidity} and {Its} {Parent} {Variables}},
	volume = {57},
	issn = {1558-8424, 1558-8432},
	shorttitle = {Two {Types} of {Physical} {Inconsistency} to {Avoid} with {Univariate} {Quantile} {Mapping}},
	url = {https://journals.ametsoc.org/view/journals/apme/57/2/jamc-d-17-0177.1.xml},
	doi = {10.1175/JAMC-D-17-0177.1},
	abstract = {Abstract Univariate quantile mapping (QM), a technique often used to statistically postprocess climate simulations, may generate physical inconsistency. This issue is investigated here by classifying physical inconsistency into two types. Type I refers to the attribution of an impossible value to a single variable, and type II refers to the breaking of a fixed intervariable relationship. Here QM is applied to relative humidity (RH) and its parent variables, namely, temperature, pressure, and specific humidity. Twelve sites representing various climate types across North America are investigated. Time series from an ensemble of ten 3-hourly simulations are postprocessed, with the CFSR reanalysis used as the reference product. For type I, results indicate that direct postprocessing of RH generates supersaturation values ({\textgreater}100\%) at relatively small frequencies of occurrence. Generated supersaturation amplitudes exceed observed values in fog and clouds. Supersaturation values are generally more frequent and higher when RH is deduced from postprocessed parent variables. For type II, results show that univariate QM practically always breaks the intervariable thermodynamic relationship. Heuristic proxies are designed for comparing the initial bias with physical inconsistency of type II, and results suggest that QM generates a problem that is arguably lesser than the one it is intended to solve. When physical inconsistency is avoided by capping one humidity variable at its saturation level and deducing the other, statistical equivalence with the reference product remains much improved relative to the initial situation. A recommendation for climate services is to postprocess RH and deduce specific humidity rather than the opposite.},
	language = {EN},
	number = {2},
	urldate = {2022-08-03},
	journal = {Journal of Applied Meteorology and Climatology},
	author = {Grenier, Patrick},
	month = feb,
	year = {2018},
	pages = {347--364},
}

@article{agbazo_characterizing_2020,
	title = {Characterizing and avoiding physical inconsistency generated by the application of univariate quantile mapping on daily minimum and maximum temperatures over {Hudson} {Bay}},
	volume = {40},
	issn = {1097-0088},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/joc.6432},
	doi = {10.1002/joc.6432},
	abstract = {Quantile mapping (QM) is a technique often used for statistical post-processing (SPP) of climate model simulations, in order to adjust their biases relative to a selected reference product and/or to downscale their resolution. However, when QM is applied in univariate mode, there is a risk of generating other problems, like intervariable physical inconsistency (PI). Here, such a risk is investigated with daily temperature minimum (Tmin) and maximum (Tmax), for which the relationship Tmin {\textgreater} Tmax would be inconsistent with the definition of the variables. QM is applied to an ensemble of 78 daily CMIP5 simulations over Hudson Bay for the application period 1979–2100, with Climate Forecast System Reanalysis (CFSR) selected as the reference product during the calibration period 1979–2010. This study's specific objectives are as follows: to investigate the conditions under which PI situations are generated; to test whether PI may be prevented simply by tuning some of the QM technique's numerical choices; and to compare the suitability of alternative approaches that hinder PI by design. Primary results suggest that PI situations appear preferentially for small values of the initial (simulated) diurnal temperature range (DTR), but the differential between the respective biases of Tmin and Tmax also plays an important role; one cannot completely prevent the generation of PI simply by adjusting QM parameters and options, but forcing preservation of the simulated long-term trends generates fewer PI situations; for avoiding PI between Tmin and Tmax, the present study supports a previous recommendation to directly post-process Tmax and DTR before deducing Tmin.},
	language = {en},
	number = {8},
	urldate = {2022-08-03},
	journal = {International Journal of Climatology},
	author = {Agbazo, Médard Noukpo and Grenier, Patrick},
	year = {2020},
	keywords = {bias adjustment, climate simulations, physical inconsistency, univariate quantile mapping},
	pages = {3868--3884},
}

@article{robin_2019,
	author = {Robin, Y. and Vrac, M. and Naveau, P. and Yiou, P.},
	title = {Multivariate stochastic bias corrections with optimal transport},
	journal = {Hydrology and Earth System Sciences},
	volume = {23},
	year = {2019},
	number = {2},
	pages = {773--786},
	url = {https://hess.copernicus.org/articles/23/773/2019/},
	doi = {10.5194/hess-23-773-2019}
}

@misc{robin_2021,
	title = {{SBCK}: {Statistical} {Bias} {Correction} {Kit}},
	copyright = {GPL-3},
	shorttitle = {{SBCK}},
	url = {https://github.com/yrobink/SBCK-python},
	urldate = {2024-07-03},
	author = {Robin, Yoann},
	year = {2021},
}

@article{higham_1988,
	title = {Computing a nearest symmetric positive semidefinite matrix},
	journal = {Linear Algebra and its Applications},
	volume = {103},
	pages = {103-118},
	year = {1988},
	issn = {0024-3795},
	doi = {https://doi.org/10.1016/0024-3795(88)90223-6},
	url = {https://www.sciencedirect.com/science/article/pii/0024379588902236},
	author = {Nicholas J. Higham},
	abstract = {The nearest symmetric positive semidefinite matrix in the Frobenius norm to an arbitrary real matrix A is shown to be (B + H)/2, where H is the symmetric polar factor of B=(A + AT)/2. In the 2-norm a nearest symmetric positive semidefinite matrix, and its distance δ2(A) from A, are given by a computationally challenging formula due to Halmos. We show how the bisection method can be applied to this formula to compute upper and lower bounds for δ2(A) differing by no more than a given amount. A key ingredient is a stable and efficient test for positive definiteness, based on an attempted Choleski decomposition. For accurate computation of δ2(A) we formulate the problem as one of zero finding and apply a hybrid Newton-bisection algorithm. Some numerical difficulties are discussed and illustrated by example.}
}

@article{knol_1989,
	title = "Least-squares approximation of an improper correlation matrix by a proper one",
	abstract = "An algorithm is presented for the best least-squares fitting correlation matrix approximating a given missing value or improper correlation matrix. The proposed algorithm is based upon a solution for Mosier's oblique Procrustes rotation problem offered by ten Berge and Nevels. A necessary and sufficient condition is given for a solution to yield the unique global minimum of the least-squares function. Empirical verification of the condition indicates that the occurrence of non-optimal solutions with the proposed algorithm is very unlikely. A possible drawback of the optimal solution is that it is a singular matrix of necessity. In cases where singularity is undesirable, one may impose the additional nonsingularity constraint that the smallest eigenvalue of the solution be δ, where δ is an arbitrary small positive constant. Finally, it may be desirable to weight the squared errors of estimation differentially. A generalized solution is derived which satisfies the additional nonsingularity constraint and also allows for weighting. The generalized solution can readily be obtained from the standard “unweighted singular” solution by transforming the observed improper correlation matrix in a suitable way.",
	keywords = "Missing value correlation, indefinite correlation matrix, IR-85889, tetrachoric correlation, constrained least-squares approximation",
	author = "Knol, {Dirk L.} and {ten Berge}, {Jos M.F.}",
	year = "1989",
	doi = "10.1007/BF02294448",
	language = "Undefined",
	volume = "54",
	pages = "53--61",
	journal = "Psychometrika",
	issn = "0033-3123",
	publisher = "Springer",
	number = "1",
}
