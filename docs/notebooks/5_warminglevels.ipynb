{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e311475",
   "metadata": {},
   "source": [
    "# Warming levels\n",
    "\n",
    "``xs.get_warming_level`` can be used to know when a given model reaches a given warming level.\n",
    "\n",
    "The arguments of ``xs.get_warming_level`` are:\n",
    "\n",
    "- `models`: Dataset, string, or list of strings. Strings should follow the format 'mip-era_source_experiment_member'\n",
    "- `wl`: warming level.\n",
    "- `window`: Number of years in the centered window during which the warming level is reached. Note that in the case of an even number, the IPCC standard is used (-n/2+1, +n/2).\n",
    "- `tas_baseline_period`: The period over which the warming level is calculated, equivalent to \"+0°C\". Defaults to 1850-1900.\n",
    "- `ignore_member`: The default `warming_level_csv` only contains data for 1 member. If you want a result regardless of the realization number, set this to True. This is only used when `models` is a Dataset.\n",
    "- `return_horizon`: Whether to return the start/end of the horizon or to return the middle year.\n",
    "    \n",
    "If `models` is a list, the function returns a dictionary. Otherwise, it will return either a string or ['start_yr', 'end_yr'], depending on `return_horizon`. For entries that it fails to find in the csv, or for instances where a given warming level is not reached, the function returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38e4c5-b693-42ea-bf9e-08862742c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xscen as xs\n",
    "\n",
    "# Multiple entries, returns a dictionary\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        [\n",
    "            \"CMIP6_CanESM5_ssp126_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp245_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp370_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp585_r1i1p1f1\",\n",
    "        ],\n",
    "        wl=2,\n",
    "        window=20,\n",
    "        return_horizon=False,\n",
    "    )\n",
    ")\n",
    "# Returns a list\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        \"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=2, window=20, return_horizon=True\n",
    "    )\n",
    ")\n",
    "# Only the middle year is requested, returns a string\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        \"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=2, window=20, return_horizon=False\n",
    "    )\n",
    ")\n",
    "# +10°C is never reached, returns None\n",
    "print(xs.get_warming_level(\"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=10, window=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b427d5",
   "metadata": {},
   "source": [
    "This rest of this notebook will demonstrate a typical workflow for showing indicators by warming levels. First, initialize your project catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec162f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "output_folder = Path().absolute() / \"_data\"\n",
    "\n",
    "project = {\n",
    "    \"title\": \"example-warminglevel\",\n",
    "    \"description\": \"This is an example catalog for xscen's documentation.\",\n",
    "}\n",
    "\n",
    "pcat = xs.ProjectCatalog(\n",
    "    str(output_folder / \"example-wl.json\"),\n",
    "    project=project,\n",
    "    create=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f349942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and regrid the data needed for the Tutorial\n",
    "\n",
    "cat_sim = xs.search_data_catalogs(\n",
    "    data_catalogs=[str(output_folder / \"tutorial-catalog.json\")],\n",
    "    variables_and_freqs={\"tas\": \"D\"},\n",
    "    other_search_criteria={\"source\": \"NorESM2-MM\", \"activity\": \"ScenarioMIP\"},\n",
    "    periods=[[2000, 2050]],\n",
    "    match_hist_and_fut=True,\n",
    "    restrict_members={\"ordered\": 1},\n",
    ")\n",
    "\n",
    "region = {\n",
    "    \"name\": \"example-region\",\n",
    "    \"method\": \"bbox\",\n",
    "    \"tile_buffer\": 1.5,\n",
    "    \"lon_bnds\": [-68.5, -67.5],\n",
    "    \"lat_bnds\": [48.5, 49.5],\n",
    "}\n",
    "\n",
    "ds_grid = xe.util.cf_grid_2d(-68.5, -67.5, 0.25, 48.5, 49.5, 0.25)\n",
    "ds_grid.attrs[\"cat:domain\"] = \"region1\"\n",
    "for ds_id, dc in cat_sim.items():\n",
    "    dset_dict = xs.extract_dataset(\n",
    "        catalog=dc,\n",
    "        region=region,\n",
    "        xr_open_kwargs={\"drop_variables\": [\"height\", \"time_bnds\"]},\n",
    "    )\n",
    "\n",
    "    for key, ds in dset_dict.items():\n",
    "        ds = xs.regrid_dataset(\n",
    "            ds=ds,\n",
    "            ds_grid=ds_grid,\n",
    "            weights_location=str(output_folder / \"gs-weights\"),\n",
    "            to_level=\"extracted\",\n",
    "        )\n",
    "        filename = str(\n",
    "            output_folder\n",
    "            / f\"wl_{ds.attrs['cat:id']}.{ds.attrs['cat:domain']}.{ds.attrs['cat:processing_level']}.{ds.attrs['cat:frequency']}.zarr\"\n",
    "        )\n",
    "        chunks = xs.io.estimate_chunks(ds, dims=[\"time\"], target_mb=50)\n",
    "        xs.save_to_zarr(ds, filename, rechunk=chunks, mode=\"o\")\n",
    "        pcat.update_from_ds(ds=ds, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddd760",
   "metadata": {},
   "source": [
    "## Subsetting the time period\n",
    "\n",
    "``xs.subset_warming_level`` is used to subset a dataset for a window over which a given global warming level is reached.\n",
    "\n",
    "Warming levels are computed individually in order to be able to calculate the ensemble weights properly (see [subsection below](#Ensemble-statistics)).\n",
    "\n",
    "The function calls `get_warming_level`, so the arguments are essentially the same.:\n",
    "\n",
    "- `ds`: input dataset.\n",
    "- `wl`: warming level.\n",
    "- `window`: Number of years in the centered window during which the warming level is reached. Note that in the case of an even number, the IPCC standard is used (-n/2+1, +n/2).\n",
    "- `tas_baseline_period`: The period over which the warming level is calculated, equivalent to \"+0°C\". Defaults to 1850-1900.\n",
    "- `ignore_member`: The default `warming_level_csv` only contains data for 1 member. If you want a result regardless of the realization number, set this to True.\n",
    "- `to_level`: Contrary to other methods, you can use \"{wl}\", \"{period0}\" and \"{period1}\" in the string to dynamically include `wl`, 'tas_baseline_period[0]' and 'tas_baseline_period[1]' in the `processing_level`.\n",
    "- `wl_dim`: The string used to fill the new `warminglevel` dimension. You can use \"{wl}\", \"{period0}\" and \"{period1}\" in the string to dynamically include `wl`, `tas_baseline_period[0]` and `tas_baseline_period[1]`. If None, no new dimension will be added.\n",
    "    \n",
    "If the source, experiment, (member), and warming level are not found in the csv. The function returns None.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_input = pcat.search(processing_level=\"extracted\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "wls = [1, 1.5]\n",
    "for wl in wls:\n",
    "    for id_input, ds_input in dict_input.items():\n",
    "        ds_wl = xs.subset_warming_level(\n",
    "            ds_input,\n",
    "            wl=wl,\n",
    "            window=20,\n",
    "        )\n",
    "\n",
    "        if ds_wl:  # check that the dataset is not None (if wl was not reached)\n",
    "            # Save and update the catalog\n",
    "            filename = str(\n",
    "                output_folder\n",
    "                / f\"wl_{ds_wl.attrs['cat:id']}.{ds_wl.attrs['cat:domain']}.{ds_wl.attrs['cat:processing_level']}.{ds_wl.attrs['cat:frequency']}.zarr\"\n",
    "            )\n",
    "            xs.save_to_zarr(ds_wl, filename, mode=\"o\")\n",
    "            pcat.update_from_ds(ds=ds_wl, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wl = pcat.search(\n",
    "    id=\"CMIP6_ScenarioMIP_NCC_NorESM2-MM_ssp585_r1i1p1f1_example-region\",\n",
    "    processing_level=\"warminglevel-1.5vs1850-1900\",\n",
    ").to_dataset()\n",
    "display(ds_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b599e",
   "metadata": {},
   "source": [
    "## Producing the horizons\n",
    "\n",
    "The extracted and subsetted dataset can be passed to ``xs.aggregate.produce_horizon`` to calculate indicators and the climatological mean. \n",
    "\n",
    "Since the years are meaningless for warming levels, and are even detrimental to making ensemble statistics, the function also formats the output such that 'time' and 'year' information is removed, while the seasons/months are unstacked to different coordinates. Hence, the single dataset outputed can contain indicators of different frequencies. \n",
    "\n",
    "The arguments of ``xs.aggregate.produce_horizon`` are:\n",
    "\n",
    "- `ds`: input dataset.\n",
    "- `indicators`: As in `compute_indicators`\n",
    "- `period`: Period to cut. If None, the whole time series is used. Useful in the case when the timeseries was already extracted by ``xs.extract.subset_warming_level``.\n",
    "- `to_level`:The processing level to assign to the output. Use \"{wl}\", \"{period0}\" and \"{period1}\" in the string to dynamically include the first value of the `warminglevel` coord of ds if it exists, `period[0]` and `period[1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_input = pcat.search(processing_level=\"^warminglevel+\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "\n",
    "for id_input, ds_input in dict_input.items():\n",
    "    ds_hor_wl = xs.produce_horizon(\n",
    "        ds_input, indicators=\"samples/indicators.yml\", to_level=\"clim{wl}\"\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_hor_wl.attrs['cat:id']}.{ds_hor_wl.attrs['cat:domain']}.{ds_hor_wl.attrs['cat:processing_level']}.{ds_hor_wl.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_hor_wl, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_hor_wl, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_hor_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7054de",
   "metadata": {},
   "source": [
    "### Reference horizon\n",
    "\n",
    "For the purpose of deltas and future ensemble statistics, a time-based reference horizon is often required. That dataset can also be created by calling ``xs.aggregate.produce_horizon``, but with the reference period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57dfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_input = pcat.search(processing_level=\"extracted\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "for id_input, ds_input in dict_input.items():\n",
    "    ds_hor = xs.produce_horizon(\n",
    "        ds_input,\n",
    "        period=[\"2001\", \"2020\"],\n",
    "        indicators=\"samples/indicators.yml\",\n",
    "        to_level=\"clim{period0}-{period1}\",\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_hor.attrs['cat:id']}.{ds_hor.attrs['cat:domain']}.{ds_hor.attrs['cat:processing_level']}.{ds_hor.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_hor, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_hor, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf33f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_hor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f9816",
   "metadata": {},
   "source": [
    "## Deltas\n",
    "\n",
    "This step is done as in the [Getting Started](2_getting_started.ipynb#Computing-deltas) Notebook, with the difference that for each simulation, the warming level and the reference horizon need to be concatenated in order to pass them to `xs.compute_deltas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c4d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_wl = pcat.search(processing_level=\"^clim+.*C\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "ref_period = \"2001-2020\"\n",
    "dict_hor = pcat.search(processing_level=f\"clim{ref_period}\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "\n",
    "for id_wl, ds_wl in dict_wl.items():\n",
    "    # for this simulation, find the accompanying reference horizon\n",
    "    level = ds_wl.attrs[\"cat:processing_level\"]\n",
    "    id_hor = id_wl.replace(level, f\"clim{ref_period}\")\n",
    "    ds_hor = dict_hor[id_hor]\n",
    "\n",
    "    # concat warming level and reference\n",
    "    ds_concat = xr.concat([ds_wl, ds_hor], dim=\"horizon\")\n",
    "\n",
    "    # compute delta\n",
    "    ds_delta = xs.aggregate.compute_deltas(\n",
    "        ds=ds_concat, reference_horizon=ref_period, to_level=f\"delta-{level}\"\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_delta.attrs['cat:id']}.{ds_delta.attrs['cat:domain']}.{ds_delta.attrs['cat:processing_level']}.{ds_delta.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_delta, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_delta, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e70707",
   "metadata": {},
   "source": [
    "## Ensemble statistics\n",
    "\n",
    "Even more than with time-based horizons, the first step of ensemble statistics should be to generate the weights. Indeed, if a model has 3 experiments reaching a given warming level, we want it to have the same weight as a model with only 2 experiments reaching that warming.\n",
    "\n",
    "<div class=\"alert alert-warning\"> <b>WARNING</b>\n",
    "    \n",
    "`xs.ensembles.generate_weights` is currently purely based on metadata, and thus cannot distinguish subtleties about which realization reaches which warming level if multiple experiments are concatenated together before passing them to the function. The results are likely to be wrong, which is why each warming level needs to be computed individually.\n",
    "</div>\n",
    "\n",
    "Next, the weights and the datasets can be passed to `xs.ensemble_stats` to calculate the ensemble statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for wl in wls:\n",
    "    datasets = pcat.search(\n",
    "        processing_level=f\"delta-clim+{wl}Cvs1850-1900\"\n",
    "    ).to_dataset_dict(xarray_open_kwargs={\"decode_timedelta\": False})\n",
    "\n",
    "    weights = xs.ensembles.generate_weights(datasets=datasets, independence_level=\"all\")\n",
    "\n",
    "    ds_ens = xs.ensemble_stats(\n",
    "        datasets=datasets,\n",
    "        common_attrs_only=True,\n",
    "        weights=weights,\n",
    "        statistics={\"ensemble_mean_std_max_min\": None},\n",
    "        to_level=f\"ensemble-deltas+{wl}C\",\n",
    "    )\n",
    "\n",
    "    # It is sometimes useful to keep track of how many realisations made the ensemble.\n",
    "    ds_ens.horizon.attrs[\"ensemble_size\"] = len(datasets)\n",
    "\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_ens.attrs['cat:id']}.{ds_ens.attrs['cat:domain']}.{ds_ens.attrs['cat:processing_level']}.{ds_ens.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_ens, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_ens, path=filename, info_dict={\"format\": \"zarr\"})\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure()\n",
    "    ds_ens[\"growing_degree_days_delta_2001_2020_mean\"].sel(\n",
    "        horizon=f\"+{wl}Cvs1850-1900\"\n",
    "    ).plot.imshow(vmin=0, vmax=400, cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_ens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
