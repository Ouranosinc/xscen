{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e311475",
   "metadata": {},
   "source": [
    "# Warming levels\n",
    "\n",
    "This Notebook explores the options provided in `xscen` to analyze climate simulations through the scope of global warming levels, instead of temporal horizons.\n",
    "\n",
    "First, we just need to prepare some data. As in other notebooks, we'll use NorESM2-MM as our example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec162f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xscen as xs\n",
    "\n",
    "output_folder = Path().absolute() / \"_data\"\n",
    "\n",
    "project = {\n",
    "    \"title\": \"example-warminglevel\",\n",
    "    \"description\": \"This is an example catalog for xscen's documentation.\",\n",
    "}\n",
    "\n",
    "pcat = xs.ProjectCatalog(\n",
    "    str(output_folder / \"example-wl.json\"),\n",
    "    project=project,\n",
    "    create=True,\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Extract and regrid the data needed for the Tutorial\n",
    "\n",
    "cat_sim = xs.search_data_catalogs(\n",
    "    data_catalogs=[str(output_folder / \"tutorial-catalog.json\")],\n",
    "    variables_and_freqs={\"tas\": \"D\"},\n",
    "    other_search_criteria={\"source\": \"NorESM2-MM\", \"activity\": \"ScenarioMIP\"},\n",
    "    periods=[[2000, 2050]],\n",
    "    match_hist_and_fut=True,\n",
    ")\n",
    "\n",
    "region = {\n",
    "    \"name\": \"example-region\",\n",
    "    \"method\": \"bbox\",\n",
    "    \"tile_buffer\": 1.5,\n",
    "    \"lon_bnds\": [-68.5, -67.5],\n",
    "    \"lat_bnds\": [48.5, 49.5],\n",
    "}\n",
    "\n",
    "ds_grid = xe.util.cf_grid_2d(-68.5, -67.5, 0.25, 48.5, 49.5, 0.25)\n",
    "ds_grid.attrs[\"cat:domain\"] = \"region1\"\n",
    "for ds_id, dc in cat_sim.items():\n",
    "    dset_dict = xs.extract_dataset(\n",
    "        catalog=dc,\n",
    "        region=region,\n",
    "        xr_open_kwargs={\"drop_variables\": [\"height\", \"time_bnds\"]},\n",
    "    )\n",
    "\n",
    "    for key, ds in dset_dict.items():\n",
    "        ds = xs.regrid_dataset(\n",
    "            ds=ds,\n",
    "            ds_grid=ds_grid,\n",
    "            weights_location=str(output_folder / \"gs-weights\"),\n",
    "            to_level=\"extracted\",\n",
    "        )\n",
    "        filename = str(\n",
    "            output_folder\n",
    "            / f\"wl_{ds.attrs['cat:id']}.{ds.attrs['cat:domain']}.{ds.attrs['cat:processing_level']}.{ds.attrs['cat:frequency']}.zarr\"\n",
    "        )\n",
    "        chunks = xs.io.estimate_chunks(ds, dims=[\"time\"], target_mb=50)\n",
    "        xs.save_to_zarr(ds, filename, rechunk=chunks, mode=\"o\")\n",
    "        pcat.update_from_ds(ds=ds, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e4fa8-554a-4647-99c1-5dafad5f278b",
   "metadata": {},
   "source": [
    "## Find warming levels with only the model name\n",
    "\n",
    "If all you want to know is the year or the period during which a climate model reaches a given warming level, then ``xs.get_warming_level`` is the function to use since you can simply give it a string or a list of strings and receive that information.\n",
    "\n",
    "The arguments of ``xs.get_warming_level`` are:\n",
    "\n",
    "- `realization`: Dataset, string, or list of strings. Strings should follow the format 'mip-era_source_experiment_member'\n",
    "- `wl`: warming level.\n",
    "- `window`: Number of years in the centered window during which the warming level is reached. Note that in the case of an even number, the IPCC standard is used (-n/2+1, +n/2).\n",
    "- `tas_baseline_period`: The period over which the warming level is calculated, equivalent to \"+0°C\". Defaults to 1850-1900.\n",
    "- `ignore_member`: The default `warming_level_csv` only contains data for 1 member. If you want a result regardless of the realization number, set this to True. This is only used when `models` is a Dataset.\n",
    "- `return_horizon`: Whether to return the start/end of the horizon or to return the middle year.\n",
    "    \n",
    "If `realization` is a list, the function returns a dictionary. Otherwise, it will return either a string or ['start_yr', 'end_yr'], depending on `return_horizon`. For entries that it fails to find in the csv, or for instances where a given warming level is not reached, the function returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38e4c5-b693-42ea-bf9e-08862742c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multiple entries, returns a dictionary\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        [\n",
    "            \"CMIP6_CanESM5_ssp126_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp245_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp370_r1i1p1f1\",\n",
    "            \"CMIP6_CanESM5_ssp585_r1i1p1f1\",\n",
    "        ],\n",
    "        wl=2,\n",
    "        window=20,\n",
    "        return_horizon=False,\n",
    "    )\n",
    ")\n",
    "# Returns a list\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        \"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=2, window=20, return_horizon=True\n",
    "    )\n",
    ")\n",
    "# Only the middle year is requested, returns a string\n",
    "print(\n",
    "    xs.get_warming_level(\n",
    "        \"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=2, window=20, return_horizon=False\n",
    "    )\n",
    ")\n",
    "# +10°C is never reached, returns None\n",
    "print(xs.get_warming_level(\"CMIP6_CanESM5_ssp585_r1i1p1f1\", wl=10, window=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ddd760",
   "metadata": {},
   "source": [
    "## Find and extract data by warming levels\n",
    "\n",
    "If you instead need to subset and analyze data, then two options are currently provided in `xscen`: `subset_warming_level` and `produce_horizon`. \n",
    "- Use `subset_warming_level` when you want to cut a dataset for a period corresponding to a given warming level, but its frequency untouched.\n",
    "- Use `produce_horizon` when you need to: subset a time period, compute indicators, and compute the climatological mean for one or multiple horizons.\n",
    "\n",
    "The two methods are detailed in the following section.\n",
    "\n",
    "### Method #1: Subsetting datasets by warming level\n",
    "\n",
    "``xs.subset_warming_level`` can be used to subset a dataset for a window over which a given global warming level is reached. Since the datasets will still have a 'time' axis after the subsetting, only a single warming level can be processed at a time, as to prevent overlapping `time` coordinates. A new dimension named `warminglevel` is created by the function, and thus it would in theory be possible to concatenate multiple results alongside that new dimension, but NaNs would need to be managed for subsequent steps.\n",
    "\n",
    "The function calls `get_warming_level`, so the arguments are essentially the same.:\n",
    "\n",
    "- `ds`: input dataset.\n",
    "- `wl`: warming level.\n",
    "- `window`: Number of years in the centered window during which the warming level is reached. Note that in the case of an even number, the IPCC standard is used (-n/2+1, +n/2).\n",
    "- `tas_baseline_period`: The period over which the warming level is calculated, equivalent to \"+0°C\". Defaults to 1850-1900.\n",
    "- `ignore_member`: The default `warming_level_csv` only contains data for 1 member. If you want a result regardless of the realization number, set this to True.\n",
    "- `to_level`: Contrary to other methods, you can use \"{wl}\", \"{period0}\" and \"{period1}\" in the string to dynamically include `wl`, 'tas_baseline_period[0]' and 'tas_baseline_period[1]' in the `processing_level`.\n",
    "- `wl_dim`: The string used to fill the new `warminglevel` dimension. You can use \"{wl}\", \"{period0}\" and \"{period1}\" in the string to dynamically include `wl`, `tas_baseline_period[0]` and `tas_baseline_period[1]`. If None, no new dimension will be added.\n",
    "    \n",
    "If the source, experiment, (member), and warming level are not found in the csv. The function returns None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a5b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = pcat.search(\n",
    "    processing_level=\"extracted\", experiment=\"ssp370\", source=\"NorESM2-MM\"\n",
    ").to_dataset()\n",
    "\n",
    "display(\n",
    "    xs.subset_warming_level(\n",
    "        ds,\n",
    "        wl=1,\n",
    "        window=20,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02b599e",
   "metadata": {},
   "source": [
    "### Method #2: Producing horizons\n",
    "\n",
    "If what you need is to compute indicators and their climatological mean, ``xs.aggregate.produce_horizon`` is a more convenient function to work with than `subset_warming_level`. Since the years are meaningless for warming levels, and are even detrimental to making ensemble statistics, the function formats the output as to remove the 'time' and 'year' information from the dataset, while the seasons/months are unstacked to different coordinates. Hence, the single dataset outputed can contain indicators of different frequencies, as well as multiple warming levels or temporal horizons.\n",
    "\n",
    "The arguments of ``xs.aggregate.produce_horizon`` are:\n",
    "\n",
    "- `ds`: input dataset.\n",
    "- `indicators`: As in `compute_indicators`\n",
    "- `periods`: Periods to cut.\n",
    "- `warminglevels`: Dictionary of arguments to pass to `subset_warming_level`. If 'wl' is a list, the function will be called for each value and produce multiple horizons.\n",
    "\n",
    "If both periods and warminglevels are None, the full time series will be used. If a dataset does not contain a given period or warming level, then that specific period will be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8c25d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_input = pcat.search(processing_level=\"extracted\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "\n",
    "for id_input, ds_input in dict_input.items():\n",
    "    # 2001-2020 will be used as our reference period. We can compute it at the same time.\n",
    "    ds_hor = xs.produce_horizon(\n",
    "        ds_input,\n",
    "        indicators=\"samples/indicators.yml\",\n",
    "        periods=[[\"2001\", \"2020\"]],\n",
    "        warminglevels={\"wl\": [1, 1.5, 2], \"window\": 20, \"ignore_member\": True},\n",
    "        to_level=\"horizons\",\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_hor.attrs['cat:id']}.{ds_hor.attrs['cat:domain']}.{ds_hor.attrs['cat:processing_level']}.{ds_hor.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_hor, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_hor, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a2168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(ds_hor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f9816",
   "metadata": {},
   "source": [
    "## Deltas and spatial aggregation\n",
    "\n",
    "This step is done as in the [Getting Started](2_getting_started.ipynb#Computing-deltas) Notebook. Here we will spatially aggregate the data, but the datasets could also be regridded to a common grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c4d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_wl = pcat.search(processing_level=\"horizons\").to_dataset_dict(\n",
    "    xarray_open_kwargs={\"decode_timedelta\": False}\n",
    ")\n",
    "\n",
    "for id_wl, ds_wl in dict_wl.items():\n",
    "    # compute delta\n",
    "    ds_delta = xs.aggregate.compute_deltas(\n",
    "        ds=ds_wl, reference_horizon=\"2001-2020\", to_level=\"deltas\"\n",
    "    )\n",
    "\n",
    "    # remove the reference period from the dataset\n",
    "    ds_delta = ds_delta.sel(horizon=~ds_delta.horizon.isin([\"2001-2020\"]))\n",
    "\n",
    "    # aggregate\n",
    "    ds_delta[\"lon\"].attrs[\"axis\"] = \"X\"\n",
    "    ds_delta[\"lat\"].attrs[\"axis\"] = \"Y\"\n",
    "    ds_agg = xs.spatial_mean(\n",
    "        ds_delta,\n",
    "        method=\"interp_centroid\",\n",
    "        to_level=\"deltas-agg\",\n",
    "        kwargs={\"lon\": -68, \"lat\": 49},\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    filename = str(\n",
    "        output_folder\n",
    "        / f\"wl_{ds_agg.attrs['cat:id']}.{ds_agg.attrs['cat:domain']}.{ds_agg.attrs['cat:processing_level']}.{ds_agg.attrs['cat:frequency']}.zarr\"\n",
    "    )\n",
    "    xs.save_to_zarr(ds_agg, filename, mode=\"o\")\n",
    "    pcat.update_from_ds(ds=ds_agg, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f96ae9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(ds_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e70707",
   "metadata": {},
   "source": [
    "## Ensemble statistics\n",
    "\n",
    "Even more than with time-based horizons, the first step of ensemble statistics should be to generate the weights. Indeed, if a model has 3 experiments reaching a given warming level, we want it to have the same weight as a model with only 2 experiments reaching that warming level. The argument `skipna=False` should be passed to `xs.generate_weights` to properly assess which simulations reaches which warming level. If the `horizon` dimension differs between datasets (as is the case here), they are reindexed and given a weight of 0.\n",
    "\n",
    "When working with warming levels, how to assess experiments is more open-ended. The IPCC Atlas splits the statistics and climate change signals by SSPs, even when they are being analyzed through warming levels, but experiments could also be considered as 'members' of a given model and used to bolster the number of realizations. Note that `split_experiments=False` is the default in `xscen`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1152f-b1c3-4b70-baee-94366fb51453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = pcat.search(processing_level=\"deltas-agg\").to_dataset_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9b6a71-0ee8-4c3e-9962-d18e4b19a1fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All realisations of NorESM2-MM are given the same weight for the first horizon, while it correctly recognizes that only the SSP585 reaches the 2nd horizon.\n",
    "weights = xs.ensembles.generate_weights(\n",
    "    datasets=datasets, independence_level=\"model\", split_experiments=False, skipna=False\n",
    ")\n",
    "display(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640fa35-d68d-4dbd-83cd-f1a1b3aa974c",
   "metadata": {},
   "source": [
    "Next, the weights and the datasets can be passed to `xs.ensemble_stats` to calculate the ensemble statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c8130d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_ens = xs.ensemble_stats(\n",
    "    datasets=datasets,\n",
    "    common_attrs_only=True,\n",
    "    weights=weights,\n",
    "    statistics={\"ensemble_mean_std_max_min\": None},\n",
    "    to_level=f\"ensemble-deltas-wl\",\n",
    ")\n",
    "\n",
    "# It is sometimes useful to keep track of how many realisations made the ensemble.\n",
    "ds_ens.horizon.attrs[\"ensemble_size\"] = len(datasets)\n",
    "\n",
    "filename = str(\n",
    "    output_folder\n",
    "    / f\"wl_{ds_ens.attrs['cat:id']}.{ds_ens.attrs['cat:domain']}.{ds_ens.attrs['cat:processing_level']}.{ds_ens.attrs['cat:frequency']}.zarr\"\n",
    ")\n",
    "xs.save_to_zarr(ds_ens, filename, mode=\"o\")\n",
    "pcat.update_from_ds(ds=ds_ens, path=filename, info_dict={\"format\": \"zarr\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds_ens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
